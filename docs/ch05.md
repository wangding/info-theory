# 第 5 章 无失真信源编码

| 串联 |  信道转移矩阵 |  信道容量  |
| :---: | ---------     | ---------- |
|   I    |  $$ [p(y/x)]=\begin{bmatrix} 1-p & p \\ p & 1-p  \end{bmatrix} $$    | $$ C_I = 1-H(p) $$  |
| I,II   | $$ \begin{aligned} [p(z/x)] &= [p(y/x)][p(z/y)] \\ &= \begin{bmatrix} 1-p & p \\ p   & 1-p  \end{bmatrix} \begin{bmatrix}  1-p & p \\  p  & 1-p  \end{bmatrix} \\  &= \begin{bmatrix}  (1-p)^2 + p^2 & 2p(1-p) \\  2p(1-p) & (1-p)^2 +p^2  \end{bmatrix}  \end{aligned} $$  |  $$ C_{I,II}=1-H[2p(1-p)] $$ |
| I,II,III | $$ \begin{aligned} [p(w/x)] &= [p(z/x)][p(w/z)] \\ &= \begin{bmatrix} (1-p)^2+p^2 & 2p(1-p) \\ 2p(1-p)   & (1-p)^2+p^2  \end{bmatrix} \begin{bmatrix}  1-p & p \\  p  & 1-p  \end{bmatrix} \\  &= \begin{bmatrix}  (1-p)^3 + 3p^2(1-p) & p^3+3p(1-p)^2 \\  p^3+3p(1-p)^2 & (1-p)^3 +3p^2(1-p)  \end{bmatrix}  \end{aligned} $$  | $$ C_{I,II,III}=1-H[p^3+3p(1-p)^2] $$ |

一、什么是编码
二、编码的分类
三、编码器的数学模型
四、一些基本概念
五、定长码

好，咱们开始吧。诸位同学，大家上午好！今天咱们开始学习第5章无失真信源编码，今天讨论三个问题，编码的分类、编码器的数学模型以及编码的一些基本概念。在开始新的内容之前，咱们还是先把以前的内容稍微总结一下，看看我们现在进展到什么位置了。从第一章概述我们就提到香农狭义信息论讨论了三个大问题，大家还记得吗？哪三个？一个是信息的度量，另一个是信道容量的计算，最后是失真的问题。通过第二章信息的统计度量和第三章离散信源的学习我们已经将信息度量的问题解决了。我们知道信息的度量是利用概率统计的方法进行间接度量的。我们通过第四章离散信道及其容量的学习，能够计算出某种信道的容量了，因此衡量不同信道的通信能力就有了标准。第三个问题是失真的问题，这个问题我们放到后面来讲，在书上的是第七章。大家现在是不是很有成就感？香农信息论的三个大问题，咱们已经解决了两个。到现在给你一个信源概率分布你可以计算信源熵以及信源冗余度，给你一个信道转移矩阵你可以计算这个信道的容量。这些是我们目前取得的成绩，是吧。
从这次课开始我们学习第5章无失真信源编码，这里面有一个核心词是“编码”，无失真信源是对编码的限定，也就是说我们讨论的是信源编码，而且是无失真的。当然我们很容易就联想到应该还有信道编码，而且应该有失真的情况发生，这些内容在后面章节我们会一一的学习。因此，我们首先应该对编码有一个基本的认识，（提问）什么是编码？大家在日常生活中有这样的体验吗？你们都见过哪些编码？（举例：计算机中的ASCII码，这是我们最容易想到的，ASCII码是英文字母的编码，汉字的编码是什么？与ASCII相对的汉字机内码是GB2312编码，还有吗？我们把思维发散开，我们的身份证号码是编码吗？对，每个人的学号，对于我来说就是教师号，甚至姓名。还有很多，比如每一本书后面的条形码，吃饭用的一卡通也有编码，银行账户的号码和密码。还有很多很多，举都举不完，最后再举一个例子，往大里说，甚至我们说的汉语，写的汉字就是编码，我们上小学查的汉语字典就是码表，我们小学学习的语文课，本质就是在学习码表，这样我们才能看得懂报纸书刊，才能与人交流，你们觉得是吗？（结论：）通过刚才我们举的大量例子，大家会发现，编码是无处不在，（提问）为什么呢？因为，信息的表示离不开编码，换句话说，任何信息总是以某种表现形式来呈现的，那这种表现形式，就是广义上的编码，当然信息是无处不在的，因此，编码也是随处可见的。
编码问题所涉及的内容和领域非常广。编码本质上就是信息的表达方式，表达的方式不同，我们说编码方法不同。因此对信息论的研究离不开对编码的讨论。
香农在狭义信息论中证明了三个重要的编码定理：无失真信源编码定理、信道编码定理以及限失真信源编码定理。这三个编码定理是狭义信息论中的重点内容。我们知道研究通信系统的目的在于提高通信系统的三个性能指标：效率、可靠性和安全性。提高的手段就是编码，提高效率用信源编码（也称为压缩编码），提高可靠性用信道编码（也称为纠错编码），提高安全性用加密编码。如何编码是一个非常实际的工程问题，但是编码的好坏，或者说编码的效率有没有一个极限，在狭义信息论中通过编码定理对这个问题进行了阐述。这三个编码定理的证明意义非常重大，因为，定理给出了编码效率的极限，因此人们在研究和改进编码方法的时候就有了目标和方向，尽量向编码定理给出的极限靠拢；而且也给出了编码好坏的衡量标准，一般讲越接近编码极限的编码应该越好。
虽然狭义信息论中没有给出具体如何编码的方法，但是香农本人和一些科学家以及工程技术人员一直在寻找接近编码极限的编码方法，因此产生了很多实用的编码方法。非常有名的编码方法有： Huffman码，Huffman发明的，它是一种变长无失真信源编码方法；(7,4) Hamming码，Hamming发明的，它是一种线性分组纠错码，同时也是循环码。等大家对这些基础知识了解和掌握以后，你可以去了解，比如：WinZIP或WinRAR是如何进行压缩的，BMP格式的图片是如何存储成JPG格式，甚至WAV格式的声音文件是如何压缩成MP3格式的。
我们把编码的知识体系分成三大块：基本概念、编码定理和编码方法。这三个部分中我们以基本概念和编码定理为主，对于编码方法则挑选有代表性的几种介绍一下。
下面开始介绍第五章无失真信源编码。这个章节的题目一上来就把编码问题限定在无失真信源这个范畴上了，当然我们有必要从整体上看一看编码到底都包括哪些内容，这样大家对编码先有一个全局的把握，然后再分块单独介绍。
编码分类	目的	手段
信源编码
（也称压缩编码）	无失真	定长	效率	减小冗余
（压缩）
		变长		
	有失真（限失真）		
信道编码（也称为纠错编码）	可靠性	增加冗余
安全编码	安全性	增加冗余
信源编码为什么可以提高效率呢？信源信息原始编码中包含大量结构化特征，这些结构特征使得大量信息不必再进行传输，可以减小实际编码的信息量，从而实现了信息的压缩。通信系统在单位时间传输能力固定的情况下，信息量越小，传输效率就越高。互联网的网站网页中嵌入的图片大多是JPG格式的，而不是BMP格式的；互联网上的音乐大多是MP3格式的，因为这些格式在编码时进行了压缩，所以传输效率高。
对离散信源的信息可以做到无失真编码，也就是说码字和信源符号是一一对应的。对于连续信源无法做到无失真编码，因为连续信源的信源符号数无穷大，连续信源的实际信息量也是无穷大，无法实现码字和信源符号一一对应。因此对于连续信源的信息编码时肯定会有失真，问题是失真的程度我们能够接受就行。定长编码和变长编码我们在后面介绍。
信道编码的目的是为了提高信息传输的可靠性，信息在信道中传输可能由于干扰的作用导致某些信息位的改变，信宿收到的信息不是原来的信息。通过信道编码可以在待传输信息中增加一些校验位，信宿通过校验算法可以发现信息是否出错，甚至有能力更改差错。举一个简单例子：待传输的信息是1，传输时把它重复三遍111，如果收到110、101、011则认为发送的是1，传输中发生了干扰。
在分类中我们仅介绍无失真信源编码，包括变长码和定长码两种情况，以及信道编码的内容。有失真信源编码和安全编码大家感兴趣可以课下自己学习。
编码是通过编码器（Encoder）这个物理部件实现的，我们对编码器建立一个数学模型可以帮助我们理解编码的数学本质。

编码器的输入是信源符号集，共有个信源符号。同时存在另一符号集，称为码符号集，共有个码符号。码符号集中的元素称为码元或者码符号。编码器的作用就是将信源符号集中的符号（或者长为的信源符号序列）变换成由基本符号组成的长为的输出符号序列。输出符号序列又称为码字，并用表示，它与信源符号是一一对应关系。
码字的集合称为代码组或码（Code）。即

而码字（Word）

其中，长度称为码字长度，简称码长。编码就是信源符号集到码字集的映射，译码就是码字集到信源符号集的映射，是编码的逆过程，。因此，若要实现无失真编码，这种映射必须是一一对应的（一一对应就可逆）。
下面我们介绍与信源编码相关的一些基本概念。
1. 二元码
若码符号集为，所有码字都是二元符号序列，则称为二元码。
若将信源通过一个二元信道进行传输，为使信源适合信道传输，就必须把信源符号变换成0，1符号组成的码符号序列（二元序列），这种编码所得的码为二元码。二元码是数字通信和计算机系统中最常用的一种码。
三元码的定义大家能给出来吗？如果码元集是为，所有码字都是三元符号序列，则称为三元码。
一般说来如果码元集，所有码字都是元符号序列，则称为元码。你们应该能够举出二元码、八元码、十元码和十六元码的例子（实际上和计算机中的二进制、八进制、十进制和十六进制数据表示是相同的）。
2. 等长码（定长码、固定长度码）
若一组码中所有码字的码长都相同，即，则称为等长码。
3. 变长码（可变长度码）
若一组码中所有码字的码长各不相同（注意：不要理解错了，并不是每个码字的长度都不相同，只要有不相同的就行，有变化就行），即任意码字由不同长度的码符号序列组成，则称为变长码。
举例：
		码1	码2



	


	00
01
10
11		0
	01
	001
	111
这个例子中信源有几个符号（即等于几），码1和码2都是几元码，哪个是定长码，哪个是变长码？（信源有四个符号，码1是定长码，码字长度为2；码2是变长码，码字长度分别是：1，2，3，3）
4. 非奇异码
若一组码中所有码字都不相同，即所有信源符号映射到不同的码符号序列，则称码为非奇异码。

5. 奇异码
若一组码中有相同的码字，即

则称码C为奇异码。
举例：
		码3	码4



	


	 0
11
10
11		0
	10
	00
	10
请大家判断上面例子和这个例子中，码1、码2、码3和码4的奇异性。（码1和码2是非奇异码；码3和码4是奇异码，因为码3和码4中）
6. 同价码
若码符号集中每个码符号所占的传输时间都相同，则所得的码C为同价码。价是价格英文为cost，就是每个码字占用信道的时间长短不同，因此传输的成本不同或者说价格不同。（参考《编码的奥秘》中关于摩尔电报码的内容和图片。）
一般二元码是同价码。本章讨论的都是同价码。对同价码来说，每个码字的传输时间都相同；而非同价码中每个码字的传输时间就不一定相同。大家能举出非同价码的例子吗？电报中常用的摩尔斯码是非同价码，其码符号点和划所占的传输时间不相同。
莫尔斯电报码的码表如下图所示，莫尔斯电码的发明人是美国的莫尔斯，他是一位画家，在40岁时突发奇想，不去画画了，开始鼓捣电，最后发明了电报。看了电报编码问大家一个问题，莫尔斯电报码是几元码？是定长码还是变长码？（摩尔斯电报码是二元变长码）



下面是发报机的原理图，发报的按键按下后电流接通，电磁铁产生电磁感应，吸引撞针在纸带上留下点和划。

7. 码的N次扩展码
假定某码C，它把信源S中的符号一一变换成码C中的码字，则码C的N次扩展码是所有N个码字组成的码字序列的集合，它与信源的N次扩展序列一一对应。

举例：
		码1	码2



	


	00
01
10
11		0
	01
	001
	111
请大家计算码2的2次扩展码。（答案如下表所示）
	码




	   	00
	  001
	 0001
	 
111111
8. 分组码（分块码）
将信源符号集中的每个信源符号映射成一个固定的码字，这样的码称为分组码。分组码顾名思义，译码的时候将接收到的序列分成一组一组的进行翻译。
与此相对应的有卷积码，对整个信源符号序列进行编码。
9. 唯一可译码
若码的任意一串有限长的码符号序列只能被唯一地译成所对应的信源符号序列，则此码称为唯一可译码，或单义可译码。否则，就称为非唯一可译码或非单义可译码。
对于定长码，如果码字是非奇异码，则它的任意有限长N次扩展码一定也是非奇异码，所以定长非奇异码一定是唯一可译码。对于变长码，则要求更严格一些，要求变长码的N次扩展码也必须是非奇异码。
举例：
		码1	码2



	


	00
01
10
11		0
	01
	001
	111
请大家判断码1和码2的唯一可译性。码1是定长码，而且每个码字各不相同，因此码1是非奇异定长码，所以码1是唯一可译码。码2的各个码字也各不相同，它是唯一可译码吗？因为它是变长码，所以不能简单的下结论。只要稍加观察就可以发现，二次扩展码与一次扩展码相同因此它不是唯一可译码。判断一个码是否是唯一可译码的具体方法后面课程有专门的介绍。
10. 即时码（逗点码、异前缀码、瞬时码、非延长码）
无需考虑后续的码符号即可从码符号序列中译出码字，这样的唯一可译码称为即时码。

举例：
		码1	码2



	


	1
10
100
1000	 	  1
  	01
	 001
	0001
码1和码2的译码情况不同，请大家判断哪个是即时码，观察即时码和非即时码的特点。（码1的码字是其它码字的前缀……）
11. 码字的前缀
设为一个码字，对于任意的，称码符号序列的前个元素为码字的前缀。可以看到即时码的前缀不是码字，而非即时码的前缀可能是合法码字。
定理：唯一可译码成为即时码的充要条件是其中任何一个码字都不是其它码字的前缀。
证明：
充分性：已知任何一个码字都不是其它码字的前缀得出码字是即时码。
因为任何一个码字都不是其它码字的前缀，所以译码的时候可以直接翻译出来所以是即时码。
必要性：已知是码字是即时码得出任何一个码字都不是其它码字的前缀。
反证法，假设有一个码字是是码字的前缀，则收到后不能立即译码，还要参考后面的码元符号，因此与即时码相违背，所以假设不成立。
各种码的关系图，圆圈代表集合。

12. 码的树图构造法
码字的构造可以用树的形式来表示，称为码的树图构造法。构造码的树称为码树。元码通常对应于元树（叉树、进制树）。当然二元码对应的就是二元树或者二叉树。
树根、叶子节点、中间节点、深度或层数、码长。
整树：每个中间节点都有个分支的树。此时构成多少个码字？（）
非整树：有的中间节点没有个分支的树。
全树：树的每个分支都达到最大的深度，构成全树。此时构成多少个码字？（）


利用树来描述即时码和非即时码的特点，利用树来描述二元码，定长码，变长码。
定长码
一般来说，若要实现无失真的编码，这不但要求信源符号与码字是一一对应的，而且要求码符号序列的反变换也是唯一的。也就是说，所编的码必须是唯一可译码。否则，所编的码不具有唯一可译性，就会引起译码带来错误与失真。
若对信源S进行等长编码，则必须满足

其中是等长码的码长，是码符号集中的码元数。
问题：如果信源有4个符号，即，编二元定长码，码符号个数，存在唯一可译码的最小码长是多少？
解：

如果我们对信源S的N次扩展信源进行等长编码。设信源，有个符号，那么它的N次扩展信源共有个符号，其中是长度为N的信源符号序列。又设码符号集为。现在需要把这些长为N的信源符号序列变换成长度为的码符号序列。根据前面的分析，若要求编得的等长码是唯一可译码则必须满足

此式表明，只有当长的码符号序列数（）大于或等于N次扩展信源的符号数（）时，才可能存在等长非奇异码。
推导：

问题：英文文章有32个符号（26个英文字母加上6个字符），即。若即对信源S的逐个符号进行二元定长编码，码长为多少？
解：

也就是说，每个英文符号至少要用5位二元符号编码才行。
从第二章已知，实际英文电报符号信源，在考虑了符号出现的概率以及符号之间的依赖性后，平均每个英文电报符号所提供的信息量约等于1.4比特，大大小与5比特。因此，等长编码后，每个码字只载荷约1.4比特信息量。也就是编码后5个二元符号只携带约1.4比特信息量。
5比特的信息量是怎么来的？实际相当与信源32个符号等概率，这是最大熵定理（信源等概率时熵最大）告诉我们的。实际自然语言中各个字母出现的频率肯定不相等，见下表。
英文字母概率表
字母	概率	字母	概率
空格	0.1859	N	0.0574
A	0.0642	O	0.0632
B	0.0127	P	0.0152
C	0.0218	Q	0.0008
D	0.0317	R	0.0484
E	0.1031	S	0.0514
F	0.0208	T	0.0796
G	0.0152	U	0.0228
H	0.0467	V	0.0083
I	0.0575	W	0.0175
J	0.0008	X	0.0013
K	0.0049	Y	0.0164
L	0.0321	Z	0.0005
M	0.0198		
这是不是就是真实的信源？我们利用这个概率模型生成一段文字，如下所示：
AI NGAE ITE NNR ASAEV OTE BAINTHA HYROO POER SET RYGAIETRWCO EHDUARU EU C FT NSREM DIY EESE F O SRIS R UNNASHOR
看上去有点像，但是不能阅读，因为字母之间没有组合出有意义的单词。实际上自然语言除了每个符号不等概率，而且符号和符号之间还有关联关系。例如字母T之后出现H、R的可能性较大，出现J、K、L、M、N的可能性极小，而根本不可能出现Q、F、X。
因此考虑到两点因素：
1. 信源符号不等概率；
2. 信源符号和符号之间有关联关系（有记忆）；
所以自然语言的信息量只有1.4bit而不是5bit。那么如何来压缩呢？
我们看一个具体的例子：
假设信源

其中关联关系为：
若不考虑记忆特征对信源做二元定长编码，其中，根据，得出。
考虑记忆特征，对信源的二次扩展做二元定长编码，根据，按理应该是，。也就是信源2次扩展之后应该有16个序列，每个序列有两个信源符号，编程码字长度应该是4，相当于每个信源符号2个码元编码，即。好像和上面没什么区别。但是实际上信源2次扩展之后并没有16个序列，而是只有4个序列，因此，相当于每个信源符号1个码元编码，即，确实实现了压缩。

五、定长码
	1、AEP和典型序列集
2、定长信源编码定理
3、讨论

好，咱们开始吧。诸位同学，大家上午好！咱们开始上课，在开始新的内容之前，按照惯例咱们先把上次课的内容复习一下。上次课的内容是第5章无失真信源编码，讲了四个问题，是什么？（什么是编码、编码的分类、编码器的数学模型和编码的基本概念）
大家需要掌握的问题有这样几个。
1、编码的本质是什么？
2、香农三定理是什么？
3、通信系统的三个性能指标是什么？
4、提高这三个性能指标的手段是什么？
5、描述编码器的概念。
6、解释二元码、定长码、变长码、奇异码、非奇异码、同价码、码的N次扩展码、唯一可译码、即时码、分组码、码字前缀、码树。
7、能够用码树描述以上编码概念的差异。
8、唯一可译码的充分必要条件是什么？
9、什么是渐进等分割性AEP？
好，这些问题都是上次课的重点内容，希望大家能够掌握。咱们开始今天的内容。上次课程我们把定长编码开了一个头，我们讨论了定长编码时码长的下限，大家还记得吗？

而且我们通过一个例题，讨论了次扩展信源做定长编码，考虑了记忆特征的情况。例题里面信源有4个符号，代表记忆特征的条件概率有4个都等于1，我们对这个信源做2次扩展，然后对扩展之后信源符号序列做定长编码，结果每个信源符号所需要的码元符号比没有扩展之前减少了，这使我们看到了码长压缩的效果。我们通过下面的图对这个情况进行分析：

这个例子比较特殊，大家知道特殊的地方在哪里吗？特殊的地方有两点，和自然语言做个比较我们可以发现：
(1) 自然语言的扩展次数（本质：符号序列的长度、记忆的长度、扩展次数）是多少？（很大，趋于无穷）
(2) 自然语言中会不会有很多符号序列的概率为零？（怀疑）
我们把这个特例推广到更一般的情况——自然语言的信源中，这样的特点还存在吗？码长可以压缩的极限是多少？非常幸运，当对信源做次扩展之后，而且当趋于无穷的时候，存在一个称为AEP的性质。AEP是（Asymptotic Equipartition Property）的缩写，是指次扩展信源当趋于无穷时个符号序列分成两大类：典型序列集和非典型序列集，而且这两个集合具有以下三条性质：
1. 典型序列集是高概率集，非典型序列集是低概率集；
2. 典型序列集中的序列接近于等概率；
3. 典型序列集中的序列数量很少；
这三条性质就是渐进等分割性（AEP）。
可以用类似上面的图进行描述：

我们下面的工作就是要对典型序列集和非典型序列集做出数学描述，然后证明AEP的三个性质。有了这个基础，我们就可以讨论定长编码的码长下限了。
当趋于无穷时，符号序列组成的集合的个数也趋于无穷大。概率论里面有一个契比雪夫大数定理讨论这其中的规律，当数量很多时，有一个必然事件会发生。（个随机变量的算术平均数和概率平均数相等，是可以任意小的正数）

如果有相同分布，则定义

在我们信息理论里，把视为随机变量，则是什么？（）

根据这个我们定义典型序列集和非典型序列集：

AEP的三个性质，用数学描述如下：

对应的物理含义：
(1) 典型序列集是高概率集，非典型序列集是低概率集；
(2) 典型序列集中的序列接近于等概率；
(3) 典型序列集中的序列数量很少；
证明如下：
(1)
 
(2)

(3)

定长无失真信源编码定理讨论了对信源做无失真压缩时，码长的下限，即码字最短可以编多短？结论是码长必须比熵要大，也就是信息熵是码长的下界。定理的详细内容我们在后面课程还要进行详细说明。要想证明这个定理，香农第一定理，定长无失真信源编码定理，需要用到AEP和典型序列集的概念。

根据上面的性质，只对典型序列集进行定长编码就可以有效的减小码长，而不会引起很大的译码错误。
证明：

4. 证明香农第一定理。
等长信源编码定理：
一个熵为的离散无记忆信源，若对信源长为的符号序列进行等长编码，设码字是从个字母的码符号集中，选取个码元组成。对于任意，只要满足

则当足够大时，可实现几乎无失真编码，即译码错误概率能为任意小（即近似为零）
反之，若

则不可能实现无失真编码，而当足够大时，译码错误概率近似等于1。
证明：








上次课讲的并联信道和这次课讲的串联信道其实都属于信道组合的问题。信道组合在通信工程中有很多实际的应用价值，如果待发送的消息比较多时，可能会用到两个或多个信道并行传输，这就是并联信道。你可以把计算机的外部存储设备和计算机主板之间连接的数据线（IDE数据线）看成是若干个BSC信道的并联。有时信息在远距离通信时需要中继，这种情况可以看成是信道串联。比如，传播电视信号的电视塔或者卫星和地面站形成的覆盖全球的通信网络。我们已经讨论了独立并联信道的情况。这次课我们讨论第二种信道组合——串联信道。

六、变长码
1、Kraft不等式和McMillan不等式
	2、唯一可译码的判别准则
	3、变长信源编码定理
	4、讨论

好，咱们开始吧。诸位同学，大家上午好！咱们开始上课，在开始新的内容之前，按照惯例咱们先把上次课的内容复习一下。上次课的内容是第5章无失真信源编码，讲了一个大问题，是什么？（定长码），定长码介绍了三个方面，AEP和典型序列集，定长编码定理以及定理的深入讨论。
大家需要掌握的问题有这样几个。
1、AEP是什么？
2、典型序列集和非典型序列集的定义是什么？
3、定长信源编码定理的内容是什么？
4、深入理解定长信源编码定理的含义。
好，这些问题都是上次课的重点内容，希望大家能够掌握。咱们开始今天的内容。上次课程介绍了定长信源编码的情况。这次课程我们继续介绍另一种编码：变长信源编码。我们从四个方面来介绍：Kraft不等式和McMillan不等式、唯一可译码的判别准则、变长信源编码定理以及深入的讨论。
Kraft不等式和McMillan不等式是证明变长信源编码定理的数学基础，就像AEP和典型序列集是证明定长信源编码定理的理论基础一样。
我们首先介绍一下Kraft不等式和McMillan不等式。
　　　　　——Kraft不等式
定理5.4.1　对于码符号的任意即时码，其码字所对应的码长为，则必满足不等式。反之，若码长满足不等式，则一定存在具有这样码长的即时码。
证明：
必要性（即时码―＞kraft不等式）
方法一：

方法二：归纳法
当，只有一个码字时（二元）
，不等式成立
当时，只有两个码字
，不等式成立
设时，不等式成立
，都是阶码树
当和增加一层并连在一起


充分性：由kraft不等式－＞存在即时码



七、变长码的编码方法
	1、Shannon码
	2、Fano码
	3、Huffman码
	4、比较

好，咱们开始吧。诸位同学，大家上午好！咱们开始上课，在开始新的内容之前，按照惯例咱们先把上次课的内容复习一下。上次课的内容是第4章离散信道及其容量，讲了两个问题，是什么？（多符号离散信道和独立并联信道的容量）
大家需要掌握的问题有这样几个。
1、多符号离散信道的数学模型是什么？
2、多符号无记忆信道的信道转移概率与单符号信道转移概率的关系是什么？
3、分三种情况：信源无记忆、信道无记忆和信源/信道都无记忆，说明多符号平均互信息量与单符号平均互信息量之间的关系是什么？ 
4、离散无记忆次扩展信道的容量是多少？
5、独立并联信道的数学模型是什么？
6、独立并联信道的容量是多少？
好，这些问题都是上次课的重点内容，希望大家能够掌握。咱们开始今天的内容。上次课程我们在单符号离散信道的基础上介绍了两种更复杂的信道：多符号离散信道和独立并联信道。这次课程我们继续介绍另一种比较复杂的情况：串联信道。
上次课讲的并联信道和这次课讲的串联信道其实都属于信道组合的问题。信道组合在通信工程中有很多实际的应用价值，如果待发送的消息比较多时，可能会用到两个或多个信道并行传输，这二种信道组合——串联信道。
					






					



我们首先考察一下串联信道的数学模型。串联信道的数学模型可以用下面的图示描述，整个信道是由第Ⅰ级信道和第Ⅱ级信道串联起来的。信道Ⅰ的特征是条件概率，信道Ⅱ的特征是条件概率。

串联后总的信道特征仍然是一个条件概率，这个条件概率是、还是？应该是条件概率。当然条件概率称为串联信的信道转移概率。问题是串联后总的条件概率与串联的两级信道的转移概率之间有什么关系？

可以看出串联后信道的转移矩阵是被串联的两级信道转移矩阵的乘积。问题是通常我们只知道第二级信道的转移概率，如果，那么我们讨论的问题就得到简化了。我们要讨论的串联信道正是这类特殊的串联信道，X、Y、Z构成马氏链。也就是信道Ⅱ的转移概率满足条件：，它的含义是信道Ⅱ的输出Z只与它的当前输入Y有关，与更以前的输入X没有关系，就是马尔可夫过程的后无效性。我们通常把时间离散的马尔可夫过程称为马尔可夫链或马氏链。这样串联信道的转移矩阵就是两个独立信道的转移矩阵的乘积：。
下面我们先研究一下串联信道中平均互信息量的一些定理，以这个为基础再来讨论串联信道的容量问题。
定理1：当且仅当时等号成立。
含义：一般情况下X、Y联合关于Z的信息量大于等于Y关于Z信息量，只有在X、Y、Z构成马氏链时，X、Y联合关于Z的信息量等于Y关于Z信息量，这正反映了后无效性的特点。
证明：

定理说明，当X、Y、Z构成马氏链时，X、Y联合关于Z的信息量等于Y关于Z信息量，这正反映了马氏链的后无效性的特点。
对于串联信道三个平均互信息量、、之间又有什么关系呢？
定理2：如果X、Y、Z构成马氏链，则有

含义：当X、Y、Z构成马氏链时，经过第Ⅰ级信道的信息量和经过第Ⅱ级信道的信息量要大于等于经过串联后整体的信息量。通过整个串联信道的信息量一般要比经过每一级信道的信息量要小，最多保持相等。
证明：

同理可得：
（请学生给出证明过程）
证明：

如果把定理2推广到个信道串联的情况，则有下面的结论。
推论：个信道串联构成马氏链，则有：


含义：个信道串联构成马氏链时，串联的信道越多经过整个信道的信息量可能越小，最多只能和原来一样多。这就是信息不增原理。
证明：略。
下面我们来讨论信道容量。信道容量的定义仍然是平均互信息量的最大值。因此有：

因为：
所以：
这说明串联的信道数量越多，串联后总的信道容量可能越小。如果串联的是无干扰信道，串联后的信道容量不减小。如果串联的是有干扰信道，串联信道的数量很大时，信道容量趋于零。
例1：计算两个BSC信道串联后的信道容量。

串联	信道转移矩阵	信道容量
I		
I,II		

从上面的n级BSC信道串联的平均互信息量图可以看出，当错误概率很小时，例如，计算串联后的平均互信息量减小的非常小。所以，串联级数n足够大时，串联信道的信道容量虽然减小，但仍有一定的数量。而实际数字通信网中，BSC信道的错误概率一般在以下，所以若干次串联后信道容量的减小并不明显。但是当比较大时，例如，计算串联后的平均互信息量减小的非常明显。当串联信道的数量比较大时，信道容量就会趋于零。
例2：有两个信道的转移矩阵分别为
 和
串联信道图如右所示：
计算该串联信道的转移概率。
解：
串联后信道X、Y、Z构成马氏链。
所以

串联后的信道转移概率。因此。
定理2非常重要，它说明通过串联信道的传输只会丢失更多的信息，如果满足，即串联信道总的信道转移概率等于第Ⅰ级信道的转移概率时，通过串联信道传输后不会增加信息的损失。当然如果第Ⅱ级信道是一个无噪无损信道，这个条件显然可以满足。上面的例2也说明了这个问题。
如果第Ⅱ级信道是数据处理系统，定理2就表示通过数据处理后，一般只会增加信息的损失，最多保持原来获得的信息，不可能比原来获得的信息有所增加，也就是说，对接收的数据Y进行处理后，无论变量Z是Y的确定对应关系还是概率关系，绝不会减少关于X的不确定性。若要使数据处理后的关于X的平均互信息保持不变，必须满足。所以定理2也称为数据处理定理。


